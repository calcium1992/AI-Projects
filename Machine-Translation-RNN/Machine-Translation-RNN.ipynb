{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T02:58:27.534198Z",
     "start_time": "2020-10-17T02:58:26.418726Z"
    }
   },
   "source": [
    "Data: https://drive.google.com/file/d/1HneKy22aVGKYlSC8p4Cttd6-DKdFdY83/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T22:54:13.823497Z",
     "start_time": "2020-12-29T22:54:13.819768Z"
    }
   },
   "source": [
    "Tutorial: https://github.com/jiuzhangjiangzuo/AICamp1.NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:29:54.208794Z",
     "start_time": "2021-01-16T01:29:53.583134Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:29:54.217772Z",
     "start_time": "2021-01-16T01:29:54.214056Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/Users/songyihe/Documents/Study/AI_Projects/large-datasets/english-chinese/segmented_train_seg_by_word.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:29:54.225002Z",
     "start_time": "2021-01-16T01:29:54.221808Z"
    }
   },
   "outputs": [],
   "source": [
    "SENTENCE_LEN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.086118Z",
     "start_time": "2021-01-16T01:29:54.227998Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000000it [00:57, 345750.18it/s]\n"
     ]
    }
   ],
   "source": [
    "eng_lines, ch_lines = [], []\n",
    "with open(TRAIN_DIR) as file:\n",
    "    num_line = 0\n",
    "    for line in tqdm(file):\n",
    "        num_line += 1\n",
    "        if num_line % 2 == 1:\n",
    "            eng_line = [i.lower() for i in line.strip('\\n').split()]\n",
    "            continue\n",
    "        else:\n",
    "            ch_line = [i for i in line.strip('\\n').replace(' ', '')]\n",
    "            \n",
    "        if len(eng_line) <= SENTENCE_LEN and len(ch_line) <= SENTENCE_LEN:\n",
    "            eng_lines.append(eng_line)\n",
    "            ch_lines.append(ch_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.091175Z",
     "start_time": "2021-01-16T01:30:52.088087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Lines: 103912\n",
      "Chinese Lines: 103912\n"
     ]
    }
   ],
   "source": [
    "print(f'English Lines: {len(eng_lines)}')\n",
    "print(f'Chinese Lines: {len(ch_lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.097009Z",
     "start_time": "2021-01-16T01:30:52.093746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deuces', 'the', 'winner', '.']\n",
      "['一', '对', '二', '胜', '。']\n"
     ]
    }
   ],
   "source": [
    "print(eng_lines[0])\n",
    "print(ch_lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.103873Z",
     "start_time": "2021-01-16T01:30:52.101533Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.248029Z",
     "start_time": "2021-01-16T01:30:52.107135Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_vocab, ch_vocab = [], []\n",
    "\n",
    "for sentence in eng_lines:\n",
    "    for word in sentence:\n",
    "        eng_vocab.append(word)\n",
    "        \n",
    "for sentence in ch_lines:\n",
    "    for word in sentence:\n",
    "        ch_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.366100Z",
     "start_time": "2021-01-16T01:30:52.250204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common English Word: [('.', 49461), ('?', 14511), ('the', 10472), ('i', 10013), (',', 9489), ('!', 8807), ('you', 7493), ('a', 6860), (\"'\", 5555), ('it', 5524)]\n",
      "Most Common Chinese Word: [('。', 44900), ('我', 15087), ('？', 14454), ('你', 9087), ('！', 8915), ('了', 8663), ('的', 8053), ('，', 7291), ('一', 6091), ('是', 5946)]\n"
     ]
    }
   ],
   "source": [
    "print(f'Most Common English Word: {Counter(eng_vocab).most_common(10)}')\n",
    "print(f'Most Common Chinese Word: {Counter(ch_vocab).most_common(10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.371516Z",
     "start_time": "2021-01-16T01:30:52.368462Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_word_to_dict(word2idx, idx2word, word):\n",
    "    if word in word2idx:\n",
    "        return\n",
    "    index = len(word2idx)\n",
    "    word2idx[word] = index\n",
    "    idx2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.431182Z",
     "start_time": "2021-01-16T01:30:52.373552Z"
    }
   },
   "outputs": [],
   "source": [
    "spec_words = ['<eos>','<start>','<end>','<unk>']\n",
    "eng_word2idx, eng_idx2word, ch_word2idx, ch_idx2word = {}, {}, {}, {}\n",
    "\n",
    "for word in spec_words:\n",
    "    add_word_to_dict(eng_word2idx, eng_idx2word, word)\n",
    "    add_word_to_dict(ch_word2idx, ch_idx2word, word)\n",
    "    \n",
    "for word in set(eng_vocab):\n",
    "    add_word_to_dict(eng_word2idx, eng_idx2word, word)\n",
    "    \n",
    "for word in set(ch_vocab):\n",
    "    add_word_to_dict(ch_word2idx, ch_idx2word, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:52.436216Z",
     "start_time": "2021-01-16T01:30:52.433451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of English Dict: 21743\n",
      "Size of Chinese Dict: 4058\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of English Dict: {len(eng_word2idx)}')\n",
    "print(f'Size of Chinese Dict: {len(ch_word2idx)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:56.445517Z",
     "start_time": "2021-01-16T01:30:52.438170Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:57.122956Z",
     "start_time": "2021-01-16T01:30:56.448318Z"
    }
   },
   "outputs": [],
   "source": [
    "data_x_in, data_y_in, data_y_out = [], [], []\n",
    "data_x_len, data_y_len = [], []\n",
    "\n",
    "for eng_line in eng_lines:\n",
    "    indices = [eng_word2idx.get(word, eng_word2idx['<unk>'])for word in eng_line] + [eng_word2idx['<eos>']]\n",
    "    data_x_in.append(indices)\n",
    "    data_x_len.append(len(indices))\n",
    "    \n",
    "for ch_line in ch_lines:\n",
    "    indices = [ch_word2idx.get(word, ch_word2idx['<unk>'])for word in ch_line]\n",
    "    data_y_in.append([ch_word2idx['<start>']] + indices)\n",
    "    data_y_out.append(indices + [ch_word2idx['<eos>']])\n",
    "    data_y_len.append(len(indices) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:57.128703Z",
     "start_time": "2021-01-16T01:30:57.124698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deuces', 'the', 'winner', '.', '<eos>']\n",
      "['<start>', '一', '对', '二', '胜', '。']\n",
      "['一', '对', '二', '胜', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print([eng_idx2word[idx] for idx in data_x_in[0]])\n",
    "print([ch_idx2word[idx] for idx in data_y_in[0]])\n",
    "print([ch_idx2word[idx] for idx in data_y_out[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:58.517521Z",
     "start_time": "2021-01-16T01:30:57.131439Z"
    }
   },
   "outputs": [],
   "source": [
    "data_x_in_pad = tf.keras.preprocessing.sequence.pad_sequences(data_x_in, padding='post', value=eng_word2idx['<eos>'])\n",
    "data_y_in_pad = tf.keras.preprocessing.sequence.pad_sequences(data_y_in, padding='post', value=eng_word2idx['<end>'])\n",
    "data_y_out_pad = tf.keras.preprocessing.sequence.pad_sequences(data_y_out, padding='post', value=eng_word2idx['<end>'])\n",
    "\n",
    "data_x_len = np.asarray(data_x_len)\n",
    "data_y_len = np.asarray(data_y_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:58.524543Z",
     "start_time": "2021-01-16T01:30:58.520096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_x_in_pad shape: (103912, 6)\n",
      "data_y_in_pad shape: (103912, 6)\n",
      "data_y_out_pad shape: (103912, 6)\n",
      "data_x_len shape: (103912,)\n",
      "data_y_len shape: (103912,)\n"
     ]
    }
   ],
   "source": [
    "print(f'data_x_in_pad shape: {data_x_in_pad.shape}')\n",
    "print(f'data_y_in_pad shape: {data_y_in_pad.shape}')\n",
    "print(f'data_y_out_pad shape: {data_y_out_pad.shape}')\n",
    "print(f'data_x_len shape: {data_x_len.shape}')\n",
    "print(f'data_y_len shape: {data_y_len.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:58.654230Z",
     "start_time": "2021-01-16T01:30:58.527516Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:58.659497Z",
     "start_time": "2021-01-16T01:30:58.656056Z"
    }
   },
   "outputs": [],
   "source": [
    "EMB_SIZE = 512   #word embedding vector length\n",
    "HIDDEN_SIZE = 512        #hidden layer size\n",
    "SRC_VOCAB_SIZE, TRG_VOCAB_SIZE = len(eng_word2idx), len(ch_word2idx)\n",
    "SEQ_MAX_LEN = SENTENCE_LEN + 1\n",
    "MAX_PRED_LEN = 10\n",
    "MAX_GRAD = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:59.700635Z",
     "start_time": "2021-01-16T01:30:58.662502Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-a76e090abf45>:35: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/songyihe/opt/anaconda3/envs/ai_camp/lib/python3.6/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:753: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.framework.ops.Operation'>):\n",
      "<tf.Operation 'decode_layer_1/decoder/assert_greater/Assert/Assert' type=Assert>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Users/songyihe/opt/anaconda3/envs/ai_camp/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)  File \"/Users/songyihe/opt/anaconda3/envs/ai_camp/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py\", line 992, in assert_greater\n",
      "    y, data, summarize, message, name)  File \"/Users/songyihe/opt/anaconda3/envs/ai_camp/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py\", line 373, in _binary_assert\n",
      "    return control_flow_ops.Assert(condition, data, summarize=summarize)  File \"/Users/songyihe/opt/anaconda3/envs/ai_camp/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)  File \"/Users/songyihe/opt/anaconda3/envs/ai_camp/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n",
      "    error_in_function=error_in_function)\n",
      "==================================\n",
      "<tf.Variable 'embedding_encoder:0' shape=(21743, 512) dtype=float32>\n",
      "<tf.Variable 'embedding_decoder:0' shape=(4058, 512) dtype=float32>\n",
      "<tf.Variable 'rnn/basic_lstm_cell/kernel:0' shape=(1024, 2048) dtype=float32>\n",
      "<tf.Variable 'rnn/basic_lstm_cell/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'decode_layer/basic_lstm_cell/kernel:0' shape=(1024, 2048) dtype=float32>\n",
      "<tf.Variable 'decode_layer/basic_lstm_cell/bias:0' shape=(2048,) dtype=float32>\n",
      "<tf.Variable 'decode_layer/dense/kernel:0' shape=(512, 4058) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "rnn_graph = tf.Graph()\n",
    "with rnn_graph.as_default():      \n",
    "    ### Initializer\n",
    "    initializer = tf.random_uniform_initializer(-0.08, 0.08)\n",
    "    tf.get_variable_scope().set_initializer(initializer)\n",
    "        \n",
    "    ### Model Inputs\n",
    "    x_in = tf.placeholder(dtype=tf.int32, shape=[None, None], name='x_in')\n",
    "    x_len = tf.placeholder(dtype=tf.int32, shape=[None], name='x_len')\n",
    "    y_in = tf.placeholder(dtype=tf.int32, shape=[None, None], name='y_in')\n",
    "    y_out = tf.placeholder(dtype=tf.int32, shape=[None, None], name='y_out')\n",
    "    y_len = tf.placeholder(dtype=tf.int32, shape=[None], name='y_len')\n",
    "    lr = tf.placeholder(dtype=tf.float32, shape=[], name='lr')\n",
    "        \n",
    "    ### I.Embedding Layer\n",
    "    embedding_encoder = tf.get_variable(name=\"embedding_encoder\",\n",
    "                                        shape=[SRC_VOCAB_SIZE, EMB_SIZE],\n",
    "                                        dtype=tf.float32)\n",
    "    embedding_decoder = tf.get_variable(name=\"embedding_decoder\",\n",
    "                                        shape=[TRG_VOCAB_SIZE, EMB_SIZE],\n",
    "                                        dtype=tf.float32)\n",
    "    # embedded_..._input: [-1, SEQ_LEN, EMB_SIZE]\n",
    "    embedded_encoder_input = tf.nn.embedding_lookup(params=embedding_encoder, \n",
    "                                                    ids=x_in)\n",
    "    embedded_decoder_input = tf.nn.embedding_lookup(params=embedding_decoder, \n",
    "                                                    ids=y_in)\n",
    "        \n",
    "    ### II.Encoder\n",
    "    encoder_lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=HIDDEN_SIZE)\n",
    "    # state: 2 * [batch_size, HIDDEN_SIZE] (2 for cell state and hidden state in LSTM)\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(cell=encoder_lstm_cell, \n",
    "                                                       inputs=embedded_encoder_input,\n",
    "                                                       sequence_length=x_len,\n",
    "                                                       time_major=False,\n",
    "                                                       dtype=tf.float32)\n",
    "        \n",
    "    ### III.Decoder - Version for Training\n",
    "    batch_size = tf.shape(x_in)[0]\n",
    "    projection_layer = layers_core.Dense(len(ch_word2idx), use_bias=False)\n",
    "    with tf.variable_scope(\"decode_layer\"):\n",
    "        sampler = tfa.seq2seq.TrainingSampler(time_major=False)\n",
    "        sampler.initialize(embedded_decoder_input, y_len)\n",
    "        decoder_lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=HIDDEN_SIZE)\n",
    "        decoder = tfa.seq2seq.BasicDecoder(cell=decoder_lstm_cell, \n",
    "                                           sampler=sampler, \n",
    "                                           output_layer=projection_layer)\n",
    "        outputs, _, _ = tfa.seq2seq.dynamic_decode(decoder=decoder,\n",
    "                                                   decoder_init_input = embedded_decoder_input,\n",
    "                                                   decoder_init_kwargs= {\n",
    "                                                       'initial_state' : encoder_state,\n",
    "                                                       'sequence_length': y_len\n",
    "                                                   })      \n",
    "        logits = outputs.rnn_output\n",
    "        target_weights = tf.sequence_mask(y_len, SEQ_MAX_LEN, dtype=logits.dtype)\n",
    "        \n",
    "    ### III.Decoder - Version for Predicting\n",
    "    with tf.variable_scope(\"decode_layer\", reuse=True):\n",
    "        sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "        decoder = tfa.seq2seq.BasicDecoder(decoder_lstm_cell, sampler, output_layer=projection_layer)       \n",
    "        outputs, _ , __= tfa.seq2seq.dynamic_decode(decoder=decoder, \n",
    "                                                    maximum_iterations=MAX_PRED_LEN, \n",
    "                                                    decoder_init_input = embedding_decoder,\n",
    "                                                    decoder_init_kwargs= {\n",
    "                                                        'initial_state' : encoder_state,\n",
    "                                                        'start_tokens': tf.fill([batch_size], ch_word2idx['<start>']), \n",
    "                                                        'end_token': ch_word2idx['<end>']\n",
    "                                                    })\n",
    "        translations = outputs.sample_id\n",
    "    \n",
    "    # Loss\n",
    "    crossentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_out, logits=logits)\n",
    "    loss = (tf.reduce_sum(crossentropy * target_weights) / tf.cast(batch_size, tf.float32))\n",
    "        \n",
    "    # Optimizer with Gradient Clip\n",
    "    optimizer_origin = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "    variables = tf.trainable_variables()\n",
    "    gradients = tf.gradients(loss, variables)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, MAX_GRAD)\n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    optimizer = optimizer_origin.apply_gradients(grads_and_vars=zip(clipped_gradients, variables),\n",
    "                                                 global_step=global_step)\n",
    "    \n",
    "    # Show Trainable Variables\n",
    "    print(*tf.trainable_variables(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:30:59.704493Z",
     "start_time": "2021-01-16T01:30:59.702330Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:40:18.780212Z",
     "start_time": "2021-01-16T01:30:59.710704Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 406/406 [04:47<00:00,  1.41it/s]\n",
      "100%|██████████| 406/406 [04:30<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一', '起', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=rnn_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Train\n",
    "    losses = []\n",
    "    beginning_lr = 4\n",
    "    for epoch in range(0,2):\n",
    "        data_indices = np.asarray(list(range(len(data_x_in))))\n",
    "        np.random.shuffle(data_indices)      \n",
    "        for index in tqdm(range(0, len(data_indices), BATCH_SIZE)):\n",
    "            batch_indices = data_indices[index: index+BATCH_SIZE]\n",
    "            batch_lr = beginning_lr if epoch < 20 else beginning_lr * 0.5 ** (one_epoch - 20)\n",
    "            _, batch_loss = sess.run([optimizer, loss],\n",
    "                                     feed_dict={\n",
    "                                         x_in: data_x_in_pad[batch_indices],\n",
    "                                         y_in: data_y_in_pad[batch_indices],\n",
    "                                         y_out: data_y_out_pad[batch_indices],\n",
    "                                         x_len: data_x_len[batch_indices],\n",
    "                                         y_len: data_y_len[batch_indices],\n",
    "                                         lr: batch_lr})\n",
    "            losses.append(batch_loss)\n",
    "            \n",
    "    # Predict for a Sample\n",
    "    sample_sentence = 'eat food'\n",
    "    indices = [eng_word2idx[i.lower()] for i in sample_sentence.split()]\n",
    "    batch_x_in = np.asarray([indices])\n",
    "    batch_x_len = np.asarray([len(indices)])\n",
    "    traslation = sess.run(translations, feed_dict={\n",
    "        x_in: batch_x_in,\n",
    "        x_len: batch_x_len,\n",
    "    })[0]\n",
    "    print([ch_idx2word[i] for i in traslation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T01:40:19.494244Z",
     "start_time": "2021-01-16T01:40:18.782681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnvElEQVR4nO3deXxV1b3+8c+XDCRhSiABQgIEJIIgAhJUkDqAIzjwa6+KrZZaLdpqa21/bXForXaQ21Ztq+21VGuxVVrrVVEcAEFEEcEgMoNMAQKBhDAEEkKmdf84JyEh04EM5+yc5/160XPOztp7f4npw8raa69tzjlERMR72gW7ABEROT0KcBERj1KAi4h4lAJcRMSjFOAiIh4V2ZonS0xMdGlpaa15ShERz1uxYsV+51zSydtbNcDT0tLIzMxszVOKiHieme2oa7uGUEREPEoBLiLiUQpwERGPatUxcBGRYCgtLSU7O5vi4uJgl9KgmJgYUlNTiYqKCqi9AlxE2rzs7Gw6depEWloaZhbscurknCM/P5/s7Gz69esX0D4aQhGRNq+4uJhu3bqFbHgDmBndunU7pd8SAgpwM7vPzNaZ2Vozm2VmMWbW1czmm9lm/2vCaVcuItLCQjm8K51qjY0GuJmlAN8DMpxzZwMRwGRgGrDAOZcOLPB/bjGfZh3gi31HWvIUIiKeEugQSiQQa2aRQBywB7gemOn/+kxgUrNXV80NzyzliicXt+QpRERa1LvvvsvAgQMZMGAA06dPb/LxGg1w59xu4HfATiAHOOycmwf0cM7l+NvkAN3r2t/MpppZppll5uXlNblgEREvKi8v5+677+add95h/fr1zJo1i/Xr1zfpmIEMoSTg6233A3oBHczslkBP4Jyb4ZzLcM5lJCXVupVfRCQsLF++nAEDBtC/f3+io6OZPHkys2fPbtIxA5lGeBmw3TmXB2BmrwJjgH1mluycyzGzZCC3SZWIiLSCR95cx/o9Bc16zMG9OvPwtUMabLN792569+5d9Tk1NZVly5Y16byBjIHvBC4wszjzXSIdD2wA3gCm+NtMAZr2T4mISBtW1/OHmzozptEeuHNumZm9AnwGlAErgRlAR+BlM7sdX8jf0KRKRERaQWM95ZaSmprKrl27qj5nZ2fTq1evJh0zoDsxnXMPAw+ftPk4vt64iIg0YtSoUWzevJnt27eTkpLCv/71L1566aUmHVO30ouItILIyEiefvpprrzySsrLy/nmN7/JkCFN+21AAS4i0komTJjAhAkTmu14WgtFRMSjFOAiIh6lABeRsFDXNL5Qc6o1KsBFpM2LiYkhPz8/pEO8cj3wmJiYgPfRRUwRafNSU1PJzs4m1NdjqnwiT6AU4CLS5kVFRQX8lBsv0RCKiIhHKcBFRDxKAS4i4lEKcBERj1KAi4h4lAJcRMSjFOAiIh6lABcR8SgFuIiIRynARUQ8SgEuIuJRCnAREY9SgIuIeJTnA3z++n1c+rtFlJVXBLsUEZFW5fkAv//V1WzfX8iBopJglyIi0qoaDXAzG2hmn1f7U2Bm3zezrmY238w2+18TWqPgOioMzmlFRIKs0QB3zm1yzg13zg0HRgJFwGvANGCBcy4dWOD/LCIireRUh1DGA1udczuA64GZ/u0zgUnNWJeIiDTiVAN8MjDL/76Hcy4HwP/ava4dzGyqmWWaWWaoP49ORMRLAg5wM4sGrgP+cyoncM7NcM5lOOcykpKSTrU+ERGpx6n0wK8GPnPO7fN/3mdmyQD+19zmLk5EROp3KgF+MyeGTwDeAKb4308BZjdXUSIi0riAAtzM4oDLgVerbZ4OXG5mm/1fm9785Z0CF9Szi4i0ushAGjnnioBuJ23LxzcrJahM08BFJEx5/k5MEZFwpQAXEfEozwe409i3iIQpzwe4iEi4ajMBro64iISbthPgSnARCTOeD/DKaYROfXARCTOeD/BK6oGLSLhpOwEe7AJERFpZ2wlwdcFFJMy0oQAPdgUiIq2rzQS4iEi48USABzI8oh64iIQbjwR4AG10GVNEwownArwhlavJqgcuIuHGEwEeSDYrv0Uk3HgjwAMaA1eEi0h48UaAN1MbEZG2xBsBHshFTCW4iIQZbwS4+uAiIrV4IsADoR64iIQbTwR4Q+F8YjlZEZHwElCAm1m8mb1iZhvNbIOZjTazrmY238w2+18TWrrYhqgHLiLhJtAe+B+Ad51zg4BhwAZgGrDAOZcOLPB/bhEnh/Obq/Yw4tF5lJZXnGijPriIhJlGA9zMOgMXAc8BOOdKnHOHgOuBmf5mM4FJLVNi7XD++RvrOFhUyqGi0hNtlN8iEmYC6YH3B/KA581spZk9a2YdgB7OuRwA/2v3unY2s6lmlmlmmXl5eadVpKYRiojUFkiARwLnAv/jnBsBFHIKwyXOuRnOuQznXEZSUtJplhnAeTSEIiJhJpAAzwaynXPL/J9fwRfo+8wsGcD/mtsyJdY/w6RyBgqoBy4i4afRAHfO7QV2mdlA/6bxwHrgDWCKf9sUYHaLVIjWORERqUtkgO2+C7xoZtHANuA2fOH/spndDuwEbmiZEhue423+BWWV8SISbgIKcOfc50BGHV8a36zV1Hv+kz7X1UZj4CISZjxxJ2Z92Vw92NUDF5Fw440Ar0f1XrfyW0TCjScC/OThkcqLmjV74IpwEQkv3gjwQIZQWqcUEZGQ4Y0Ar2d7RbUEVwdcRMKNNwK8nnR2VL+ZRwkuIuHFGwFez/aKCvXARSR8eSLA67Ny16Gq98pvEQk3gd6JGVT13cjzvVkr620jItLWeaIHHshdlppGKCLhxhMBHsj4iOJbRMKNJwI8kHBWB1xEwo03AvzkMfA6wlqLWYlIuPFEgAdE+S0iYcYTAR7QRcxWqENEJJR4I8BrDaHUjmuNgYtIuPFGgAfURgkuIuHFGwEeQPdaPXARCTceCfAA2rR8GSIiIcUTAR4I3YkpIuGm7QR4sAsQEWllngjwQJ5KrwQXkXDjjQAPaB64ElxEwktAy8maWRZwBCgHypxzGWbWFfg3kAZkATc65w62RJGBPLxYQ+AiEm5OpQd+qXNuuHMuw/95GrDAOZcOLPB/bhHVszmQBxyLiISDpgyhXA/M9L+fCUxqcjUBcFX/U8d2EZEwEmiAO2Cema0ws6n+bT2cczkA/tfude1oZlPNLNPMMvPy8k6rSFfj6fN1j3ZrGqGIhJtAH6l2oXNuj5l1B+ab2cZAT+CcmwHMAMjIyDitlK2+0z0vreTo8bIG24iIhIOAeuDOuT3+11zgNeA8YJ+ZJQP4X3Nbqsjqnet31+1ttI2ISDhoNMDNrIOZdap8D1wBrAXeAKb4m00BZrdUkYH0r+/65wqy9he2XAkiIiEmkCGUHsBrZlbZ/iXn3Ltm9inwspndDuwEbmipIgPtXa/KPkRaYoeWKkNEJKQ0GuDOuW3AsDq25wPjW6IoERFpnCfuxHz9893BLkFEJOR4IsBX7GiRGzxFRDzNEwEeHRkRUDvNRBGRcOKNAI/wRJkiIq3KE8nYPtITZYqItCpPJKMCXESkNk8kY3SAAa41wUUknLSpABcRCSeeSEZdxBQRqc0TyRilHriISC2eSEb1wEVEavNEMraPCvAipq5hikgY8USAqwcuIlKbJ5LxkoFJAbVTD1xEwoknAnxA9068fOfoRttVKMFFJIx4IsABItpZo20U4CISTjwT4FERjQd4ecWJ97sOFPHXxdtasCIRkeAK9Kn0QRdID7y8Wg/8tr9/ypbco1w3vBc9Ose0ZGkiIkHhmR54QEMoFScC/EhxqW+bhlVEpI3yTIAHorxagBuNB76IiJe1qQCvq7etDriItFWeCfBAetQ1euD+5hpCEZG2yjMBHojH3tlI2rS3OF5WXrWteqiLiLQlAQe4mUWY2Uozm+P/3NXM5pvZZv9rQsuVCX27xXFGUgduGJnaaNvDRaVV/fUyBbiItFGn0gO/F9hQ7fM0YIFzLh1Y4P/cYmKiIljww0sYlda18cbVRlsqe+BzVu/hYGFJC1UnItL6AgpwM0sFJgLPVtt8PTDT/34mMKlZK6vHtcN6cal/bZROMfVMY3dg/kHwsnLHnkPHuOelldz90metUaKISKsItAf+e+DHQLV7HenhnMsB8L92r2tHM5tqZplmlpmXl9eUWgGIjY7gyZuGA/DlESl1tikurWD3oWOArwd+vMxX9h7/NhGRtqDRADeza4Bc59yK0zmBc26Gcy7DOZeRlBTYqoKNiY+LZsm0cfzs2iF1fv2i375f9b6soqLONiIiXhfIrfQXAteZ2QQgBuhsZv8E9plZsnMux8ySgdyWLPRkKfGxAbXTLBQRaasa7YE75+53zqU659KAycBC59wtwBvAFH+zKcDsFquyCcoqHE5zwUWkDWrKPPDpwOVmthm43P855JRXOCo74Vn5RRoHF5E245QC3Dm3yDl3jf99vnNuvHMu3f96oGVKbJrS8ooad2Ne+fvFQaxGRKT5tJk7MScN71Xn9vIKR1l59VUKy1qrJBGRFtVmArxyauHJdh4oIvtgUesWIyLSCjzzQIfGVN64c7JH3lzfypWIiLSONtMDPxWalSIibUFYBvjflmQFuwQRkSYLywDfkFMQ7BJERJrM82Pgb94zlo71LWolItKGeT75hqZ2OeV9ikvLG28kIhLiwnIIZc7qHI4e13xwEfG2sAxwgCPFpcEuQUSkSdpUgL/2nTEBt9UqhSLidW0qwJO7BLbELFD1kAcREa9qUwFeWl4zlEf371Zv2+Olpx/gBcWlbMs7etr7i4g0B8/PQqkuNSGWuy4+gy+lJ2LA4F6dGf7o/DrbFped/kyUG59Zysa9R8iaPvG0jyEi0lRtqgduZky7ehAXDkhkzIBEoiLq/+tV74EfLCzhqt8vZktuYL3qjXuPNLlWEZGmalMBfrKGAvyl5Tur3i/YmMvGvUd46PU1fOfFFRSeNMUw5/CxOodMTh6yERFpTW08wOteoRDgzVV7KCop47OdB6vafbLtAG+v2cvcdXtrtB392ELGPf5BrWPohiARCaY2NQZ+svqWmK00+GdzAbj/6kE1trePjAjo+MWlFXSKOb3aRESaqk33wAP11MItNT5n7jjAN//+aa0hkvnr99X4/NrKbADyjx7XErUi0urafIA/fsMw5t13EXO+O7beNiffVv/8kiwWbsxlR37NJ/l864XMGp9//fZG1u4+zMhfvsfrn+9uvqJFRALQ5gP8KyNTObNHJ85O6cL6R6/k42njuOys7kwe1bvRfZ987wtW7TrUYJuVOw8CsHx7SD7TWUTasDYf4NXFRUfSKz6WZ6eMYvQZNW/y+cq5qbXav7U6h+v/tKTGttkn9bSPHvddyOwQ3aYvJ4hICGo0wM0sxsyWm9kqM1tnZo/4t3c1s/lmttn/mtDy5Ta/Tv61xG+5oE9A7Zds2V/jc4F/UaxnP9rOki37cc6RfbCIO2Z+WvU1EZGWEEi38Tgwzjl31MyigI/M7B3gy8AC59x0M5sGTAN+0oK1Nqurzu7JHWP7cc+4ARhGl7gosqZPpPB4GRv3HqF3QiztoyIY9si8GvsVltScOpi1v7Dq/deeXcaNGam8nOm7uDn78z3cekHflv/LiEhYarQH7nwq72KJ8v9xwPXATP/2mcCkliiwpbSPjOChawYTHxdNl7ioqu0d2kcysm8C3TvH0CU2ijsv6l9jv7dW59T4/M7amnPGK8MboEIrHopICwpoDNzMIszscyAXmO+cWwb0cM7lAPhfu9ez71QzyzSzzLy8vGYqu/XcPW4AAD+9ZjBJndpXbZ920tzxulRoaqGItKCAAtw5V+6cGw6kAueZ2dmBnsA5N8M5l+Gcy0hKSjrNMoOnc0wUW389gdvH9qNdtfuCzu7VpWr8vD6PvLme3YeOtXCFIhKuTmkWinPuELAIuArYZ2bJAP7X3OYuLlRE+JM7wn9n50MTz2JseiIf/WRco/ve/+qaWmurADjnWJ19iDKtpyIipymQWShJZhbvfx8LXAZsBN4ApvibTQFmt1CNIeO8fl0BuG54LwC6xEZx7/h0XrrjfLpXG16pbvEXeUz60xKufHIxU1/I5J+f7OB4WTlz1+3juqeX8OR7X7Ra/SLStlhjt4Cb2Tn4LlJG4Av8l51zj5pZN+BloA+wE7jBOdfg3SwZGRkuMzOzoSYh7VhJORv3FjCiT+0Zk0UlZVzx5GKyDx5j2QPjKSopZ+nWfB54bU2ttlNG96Wk3DFr+U6uGtKTZ24dWfW1krIKoiKs0XVcRCR8mNkK51xGre2tuYaH1wO8MYePlZJbUEx6j05V2+as3sNv3t3EzgNFDewJ378snXP7JPD1vy3nrovPCOgiqYiEBwV4kKVNewvwPTUo+2DjFzb1tB8RqVRfgOv+71ay+EeXEhVpbM8r5KvPLgt4v4oKx8KNuYxNTyQmKrBlbkUkPITVWijB1KdbHMldYhkzIJGHJp7VaPv3N+ayZMt++j/wNne8kMlfF2/jN+9u5FBRCQDPfriNoQ/P1TK2ImFMQyhBcKCwhHN/MZ/z+3Xlr1MyOOfn8xrdJz4uikNFpQzrHc+XBiTy9Psn1jAf0qszv5x0dp0XV0XE+zQGHmLmrttLRt8EunVsz3vr99EvqQPj63hs26nImj6RsvIKikrL6RwT1fgOIuIJCnAPOVRUwqNvrmdE3wR++vragPebODSZt9b41mrZ/tgEzIzl2w/whwVf8NyUUcRERbCvoJgjxaUM6N6pkaOJSKjQRUwPiY+L5ombhgPUCPBvXtiPzrGR/P69zQB0jolkbHoib6/xLahVGd4ALy3fydrdBcxavhOAdXsKWLv7MA+/sQ6ALb+6GgdERTR+GaTweBm7Dx3jzB4KfZFQoh54iCsuLSeynXHoWCld46IB6P/A2wB89JNLeWrBFv6duavR4/TsHMPeguKqz6PSEsgvLGHsgERKyiq4blgvxgxIBGDW8p1Mf2cjs+++kLTEDtz63DI+3LyfLb+6msgAAl9Empd64B5VOXUwseOJW/Wfv20Uuw8eIzUhjvP6deXfmbt4YMIgBvbszJS/La/zONXDG+DTLN+j4Lbl+dYzf3tNDh/86FIu+s37HPGv3TJ33V4mjUjhw82+h1gMePAd7ryoP/delk7cSU8gqqhw/HnRFm7M6E33zjHN8DcXkcaoB+5xzjm25B6tuvsz5/AxRj+2sOrrXWKjuO+ydH7+5vp6j3H54B7MX7+Pr53fhxeX7Wz0nDdl9MYMPvgij39PHU2fbnFsyT3KZU98QN9ucbz/w0s4VlpOTFQEb6zazXXDUth1oIieXXzB/mnWAb6UnkRJWQXRkerRizRGFzHDSElZBXlHj3O4qJTBvTpzpLiUof6pii/ecT5fe3YZURHGQxMH8z+LtvLit87npr8sZf/Rkqpj9Oka1+jt/5WG947n82oPf753fDp/XLiZ/zcihVc/2803xqTx94+zAPjOJWfw50Vb+fPXzuU7L34GwP1XD+LOi88AYM+hYyzffoBJI1LqPd/5v36PoSnxPDul1s+zSJukAA9zadPeonfXWD788Tg27i2gW4f2NR5Q8fyS7Tzi76U/dfMIxg5IJDY6gkE/fbdV6tv26wlVY/sAa35+BTvyi4iPiyI1IQ7wrTXTOSaSfvf72mm5AQkXGgMPcwt/eDEJ/ougg3p2rvX1m0b1pqiknAlDk+mX2KHW15+/bRS3Pf9p1eeRfRP4+ui+/PvTXXy8Nb9qe1q3OMamJ7J531GWbW9wccoaKnvolb7590+rxum3PzaB3CPHOf/XC7h9bL+qNrOW72TyqN71rtzonGNfwfGqoZuT7TpQRO+ucQHXKBJq1AOXBlUuwrX651dU3TF64YBuPDRxMGcl+/4h+Gjzfm55zre+y9L7x5HcJZbZn+/m3n993mx1fCk9sepianU3ZfTmZ9cOpkP7SLbkHqVzbCTdO8VQVFLGo2+u51+f+mbonNxbX779ADf+ZSl/mDyc64fXP1wjEgrq64HrCpIEpFP7SK4a0pPoyHa8eMcFVeENMDY9sep95R2g1w3rxZJp43j7e1+q83hZ0ycyNKVLwOevK7wB/p25iyEPz+UXc9Zz2RMfcPOMT8g/epwZi7dVhTfAy9WmWpaWV1TNj//gizw+2ZZP7pETs3SOl5WzI78w4NpEgkVDKBIQM6vx4ImTPTTxLH751gbioiOq2qfEx5ISH8tTN4/gYFEJI/smcMMzS7l3fDoAveJjWLP7MABXDO7BvPX7AJhx60heW7mbd9buDbi+5z7aDsDWvEJG/vK9Wl//8Sur2ZFfyAsf7+C8fl1ZsNH3BMDDRaVMnvEJA7p35L0fXAzAH97bzJ8XbWXxjy6lT7e6h1gKikuJateO2GitECnBoyEUadCHm/PYvr+Qr49Oa/ZjHygs4e8fZ3HbmDQSOkTz3vp9rN59mB9cfibgexjGPS+trLXfoJ6deHZKBu0jI9h/9DhPv7+Ft1bn8K0v9eOvH24/7XpWPXwF7SPbcdc/V7BoUx53XtSfH181iG+9kEm3DtHcefEZzF+/j6+MTOG8Xy1gaEoX3vzuWJxzVDiqHnr91pocHnt7I699ZwxFJeUcKy2v8RuLyKnSLBTxnM92HuTLf/6YLrFRfDxtHNv3F3J2PcMuzrmqi5lPzNvEHxduqbPdyL4J/OXWkRwqKuWyJxpfPOyPN4/ge7Nq/iPSKSaSI8W+m53e+t5Yfjt3E4s25XHNOcnMWX1iOYOnbh7Bd/37/vdXhnL98BRioiLYuLeAuKjIenv3IifTLBTxnJhI3/BE1w7RdGgfWW94AzVmoowZkMgfF27hyZuGERsVwZBeXXhp+U6uOSeZIb18x0js2J5hveNZ5Z+/nhIfy+5DtZ+UdHJ4g2+cvzLAJ/7xo6rt1cMbqApvgJ/87xr2HCpmeO94bvu7bzbPUzeP4Lx+Xelx0p2rpeUVPPjaGuLjorn/6kEUlZRTWFJGO7Mad+SKqAcuIetIcSnnPDKPZ24ZyZVDep7SvoFMEdy+v5AZi7dy24X9SOvWgd2HjnHp7xYB8L3x6fxxweZa+3x5RApP3DScF5Zm8bPZ606ppvrceVF/CorL+MlVA2nXznh/Y269M3gq16P5zosruGJwTyaNSGFHfiEbco5w1dm+79GKHQcY3juB3QeP0adbHMfLyomOaHfKD8quqHC0a6eHa4cCDaGIBGBL7hG25RUyblB3MnccZPKMTwAY0SeelTsP8c0L+/GzaweTfbCIsf/9fp3H+K+RqbyyIrvFaqw+VPPMLSO5658rAHjvBxdzoLCEG/+ylDN7dOSLfUf5x+3ncetzy7ntwjSOFJdx3+VnkhIf2+g59hw6xpjpC3nq5hFcO6wXew4dI7KdaZ2bIFGAi5yGoT+fy5HiMpZMG8c/lu7g25ecQZdY31TJHfmFLNmSz8GiEkaf0Y0ze3TiodfW8MCEs1i6LZ+/Lcni4vREbrmgL/e9/DlLtuTXOPbXR/flhaU7mq3W744bwHMfbaeopLxq24ShPauWGwbon9iB+y4/k4lDk/nRK6v52gV9OLdPAq9+ls2O/CLu819AXrJlP197dhln9ujIy3eOZvij8zGD7Y8Ffvfr8bJyotq1Uy++GSjARU7D6uxDzFq+k19NGtqkIDp8rJRhj5x4dN43xqTx8LWDWbx5P8NT43ltZTafZh2sWtN94jnJ3DG2HwXFZby/MZepF/VnzPSF9R3+lE3/8lCmvboGgHGDurPQP61yxUOXsXhzHs99tJ21uwtq7Vd5Q9TBwhIuf3IxSZ3a87/fHl1rdcrS8grSH3yHOy/uz/1XN/4M2MY45/j7x1l8eUQqXeLC72lTpx3gZtYbeAHoCVQAM5xzfzCzrsC/gTQgC7jROXewoWMpwCWc5R05TqeYSB6ft4l7Lk2vFUSFx8t4Z+1eZn++m6dvPrfG151zVWvAgG+u/J8WbWXVrkP07RbHTaN685t3NzW5xrjoiBo9+JNdfXZP3lm7l24doskv9C1+9tv/Ooe46EjSEuN47bPdTBqRQlKn9pz/6wVA7btgcwuK+fOirfzwijPpdNKj/w4fK2VnfhFDU09csP7gizyOl5Yz9R8ruOacZJ7+6rmA7xrJyfu3VU0J8GQg2Tn3mZl1AlYAk4BvAAecc9PNbBqQ4Jz7SUPHUoCLnL61uw+zIaeA3l3juKB/NyoqHI/OWc+NGb0Z3Ktz1bIHlc5J7cLq7MNBqbVyiWKAzb+6mvQH3wEgvXtHDh0rJe/IccA3DXPp1nwGdO/I+pyCqn+EnpuSwci+CYx//APyC0uIaGeUVzgy+ibwyrfHMPPjLB5+Yx2f3D+eiHbGrOU7ufvSAf5VMR0j+3Y9pXqLS8vJPniMAd07Ntv3oDmd9jRC51wOkON/f8TMNgApwPXAJf5mM4FFQIMBLiKn7+yULjWmUrZrZ/z8uiG12mVNn8is5Tu5ZGAS4x//oKpH/dId5xMd2Y631uTw/JIsAD598DIi2xkjfjG/agnhWy/oy6WDknjxk51Vd6yeqsrwBniq2pz8zblHa7SrPg2zuttnZvLghLOqevnlFb6OZml5BSVlFfzpfd8xL3hsQdU+GX0T+Oqzy6q+B/X5eMt+fvTKal6+azQp8bH8J3MXf1y4mV0HjvHGPRfSP6kjHdt7Y4b1KY2Bm1kasBg4G9jpnIuv9rWDzrmEOvaZCkwF6NOnz8gdO5rvoo2InLDrQBFHj5fVuOtzyZb9PDH/C35/0/Aa0ypLyyvYllfIwJ6+B4Fs319IcpcY3ly1h4nnJBMXHVlj2GZQz05MGZPG6P7duMQ/1bKl1beA2VnJndl7+BgHi0prbK9+09W949NJ79GRa87pxdKt+Tzw2hpuGtWbGzN6c8WTi9l/1PcbwOM3DOOH/1lV4zjfvuQMfnLVIAA25BQwd91e7h2ffkrTMD/eup8DhSVcc06vU/o716fJFzHNrCPwAfAr59yrZnYokACvTkMoIt6y/+hxCo+X0bfbiSWGhz48l8gIY8EPL+GtNTn89PW1dGwfydHjZUwY2pPUhDhmLN4GnJhP3z+pAynxsVWBHB8XRUp8LOv2FPDo9UMoLi3n129vrHX+lPhYfnzVwIBWthzUsxMb9x6pse3WC/ryj09OvdM4qGcnRp/Rreo3lY+njaNXtemX89fv49kPt/HcN0ZhgAMysw5wycDurNtzuOo3izfuuZAb/7KU7192Jnf5H1pyOpoU4GYWBcwB5jrnnvBv2wRc4pzL8Y+TL3LODWzoOApwEe8rPF6GGbVmnuQWFJPUqT1mvvHqiHZG7pFibvrLJ/zuhnMY2bcruUeKWbbtAGMHJJLQIbrGEggLNuzj9pmZVRdKAR778lCuHNKTyTOWsvdwMQX+O2ABhvTqzLo9tWfKtIShKV0Y2TeBsQMSKSotr/MOXYA/ffVc3t+UW3UfwE+vGcwv5vgelNKUB5A05SKm4RvjPuCc+3617b8F8qtdxOzqnPtxQ8dSgItIQ7blHaV31zh+MWc91w9PYWTfE7/UO+fYW1Bc9czXrOkT+dtH23l0Ts3nvZ6V3JkNOQU8OOEsunduT4/OMTw+b1PVA0JS4mN58Y7zawwFzbh1JFP/saJF/25zvju2weUgGtKUAB8LfAiswTeNEOABYBnwMtAH2Anc4Jxr8BEsCnARaaoFG/aRkhDLoJ6dcc6Rc7iYDtGRPDJnHa9+tptlD4znyflfcP/VZ1VNxTx8rJQRj86jwsH7//8S+iV2IGt/Ib+Zu5HJo/pw0ZlJrN9TwJk9OjLwp+9WXTRtyKqHr+DNVXt46PW1tb5218Vn8MwHW2tse/3uCxneO/60/s66kUdE2rTS8goOFZXWeNZrdcu3H2DT3gJubWRp5Gc+2Mr0dzay8qeX89t5m7gxozeT/rQEgMHJnRl/VneuH96LAd19F4C35R1l3OMnVrb8xaSzufWCvrWmdW7+1dVERZzeM3QU4CIiTXD0eFm90wt/OWc9hSXlPHztYGKifKtoVgb4wh9e7PsNoE+DczwapOVkRUSaoKG54Q9dM7jWtt/dMIyenWPon9RyNwcpwEVEWsB/jUxt8XPoocYiIh6lABcR8SgFuIiIRynARUQ8SgEuIuJRCnAREY9SgIuIeJQCXETEo1r1VnozywNO94kOiUDt1d2DLxTrCsWaIDTrCsWaIDTrCsWaIDTrau6a+jrnkk7e2KoB3hRmllnXWgDBFop1hWJNEJp1hWJNEJp1hWJNEJp1tVZNGkIREfEoBbiIiEd5KcBnBLuAeoRiXaFYE4RmXaFYE4RmXaFYE4RmXa1Sk2fGwEVEpCYv9cBFRKQaBbiIiEd5IsDN7Coz22RmW8xsWiue929mlmtma6tt62pm881ss/81odrX7vfXuMnMrmyhmnqb2ftmtsHM1pnZvSFSV4yZLTezVf66HgmFuvzniTCzlWY2J4RqyjKzNWb2uZllhlBd8Wb2iplt9P+MjQ5mXWY20P89qvxTYGbfD/b3yszu8/+crzWzWf6f/9avyTkX0n+ACGAr0B+IBlYBg1vp3BcB5wJrq237DTDN/34a8N/+94P9tbUH+vlrjmiBmpKBc/3vOwFf+M8d7LoM6Oh/HwUsAy4Idl3+c/0AeAmYEwr/Df3nygIST9oWCnXNBO7wv48G4kOhLv/5IoC9QN9g1gSkANuBWP/nl4FvBKOmFvlGN/M3azQwt9rn+4H7W/H8adQM8E1Asv99MrCprrqAucDoVqhvNnB5KNUFxAGfAecHuy4gFVgAjONEgAf9e0XdAR7s71VnfzBZKNVV7fhXAEuCXRO+AN8FdMX3WMo5/tpavSYvDKFUfrMqZfu3BUsP51wOgP+1u397q9dpZmnACHy93aDX5R+q+BzIBeY750Khrt8DPwYqqm0Ldk0ADphnZivMbGqI1NUfyAOe9w85PWtmHUKgrkqTgVn+90GryTm3G/gdsBPIAQ475+YFoyYvBLjVsS0U5z62ap1m1hH4X+D7zrmChprWsa1F6nLOlTvnhuPr9Z5nZmcHsy4zuwbIdc6tCHSXOra11H/DC51z5wJXA3eb2UUNtG2tuiLxDRn+j3NuBFCIbygg2HVhZtHAdcB/Gmtax7bm/rlKAK7HNxzSC+hgZrcEoyYvBHg20Lva51RgT5BqAdhnZskA/tdc//ZWq9PMovCF94vOuVdDpa5KzrlDwCLgqiDXdSFwnZllAf8CxpnZP4NcEwDOuT3+11zgNeC8EKgrG8j2/+YE8Aq+QA92XeD7h+4z59w+/+dg1nQZsN05l+ecKwVeBcYEoyYvBPinQLqZ9fP/KzwZeCOI9bwBTPG/n4JvDLpy+2Qza29m/YB0YHlzn9zMDHgO2OCceyKE6koys3j/+1h8P+Qbg1mXc+5+51yqcy4N38/NQufcLcGsCcDMOphZp8r3+MZP1wa7LufcXmCXmQ30bxoPrA92XX43c2L4pPLcwappJ3CBmcX5//84HtgQlJpa6oJDM180mIBvtsVW4MFWPO8sfGNcpfj+Fb0d6Ibvothm/2vXau0f9Ne4Cbi6hWoai+/Xr9XA5/4/E0KgrnOAlf661gI/828Pal3VznUJJy5iBvt71R/frIRVwLrKn+lg1+U/z3Ag0//f8XUgIdh14bsong90qbYt2DU9gq+Dshb4B74ZJq1ek26lFxHxKC8MoYiISB0U4CIiHqUAFxHxKAW4iIhHKcBFRDxKAS4i4lEKcBERj/o/ycFD+TeDAzAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(losses).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
